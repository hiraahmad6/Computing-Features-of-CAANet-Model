{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computation_Lower_Training_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNzoM-PSOClo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################### Particularly Compute Features for low training dataset ##############################\n",
        "#### Similarly, we can compute features for mid training , high training, low testing, mid testing and high testing datasets  #####\n",
        "\n",
        "#### By changing paths of images, weights to use, and variables ######"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkyetcv6UOmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################## Python 2 #############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhT1s_txLmKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "low_train = 1581\n",
        "mid_train = 2204\n",
        "high_train = 852\n",
        "low_test = 348\n",
        "mid_test = 126\n",
        "high_test = 54"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0n6OD5XLrjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lower_training=[]\n",
        "mid_training =[]\n",
        "high_training =[]\n",
        "lower_testing =[]\n",
        "mid_testing =[]\n",
        "high_testing =[]\n",
        "\n",
        "\n",
        "#Give paths of lower_training images\n",
        "for i in range(low_train):\n",
        "  lower_training.append('part_B_final/train_data/images/IMG_'+str(i+1)+'.tiff')\n",
        "\n",
        "#for i in range(mid_train):\n",
        "  #mid_training.append('part_B_final/train_data/images/IMG_'+str(i+1)+'.tiff')\n",
        "\n",
        "###Similarly add other paths according to lower, mid, and high dataset , I am just showing the working of lower training dataset\n",
        "\n",
        "### I have done it separately, I have training images on separate folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuQEyGbtLtse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(lower_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-her9OiLwhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import dataset\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG3H6NAcLO5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class ContextualModule(nn.Module):\n",
        "    def __init__(self, features, out_features=512, sizes=(1, 2, 3, 6)):\n",
        "        super(ContextualModule, self).__init__()\n",
        "        self.scales = []\n",
        "        self.scales = nn.ModuleList([self._make_scale(features, size) for size in sizes])\n",
        "        self.bottleneck = nn.Conv2d(features * 2, out_features, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.weight_net = nn.Conv2d(features,features,kernel_size=1)\n",
        "\n",
        "    def __make_weight(self,feature,scale_feature):\n",
        "        weight_feature = feature - scale_feature\n",
        "        return F.sigmoid(self.weight_net(weight_feature))\n",
        "\n",
        "    def _make_scale(self, features, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        multi_scales = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.scales]\n",
        "        weights = [self.__make_weight(feats,scale_feature) for scale_feature in multi_scales]\n",
        "        overall_features = [(multi_scales[0]*weights[0]+multi_scales[1]*weights[1]+multi_scales[2]*weights[2]+multi_scales[3]*weights[3])/(weights[0]+weights[1]+weights[2]+weights[3])]+ [feats]\n",
        "        bottle = self.bottleneck(torch.cat(overall_features, 1))\n",
        "        return self.relu(bottle)\n",
        "\n",
        "class CANNet(nn.Module):\n",
        "    def __init__(self, load_weights=False):\n",
        "        super(CANNet, self).__init__()\n",
        "        self.seen = 0\n",
        "        self.context = ContextualModule(512, 512)\n",
        "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
        "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
        "        self.frontend = make_layers(self.frontend_feat)\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 512,batch_norm=True, dilation = True)\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        if not load_weights:\n",
        "            mod = models.vgg16(pretrained = True)\n",
        "            self._initialize_weights()\n",
        "            for i in xrange(len(self.frontend.state_dict().items())):\n",
        "                self.frontend.state_dict().items()[i][1].data[:] = mod.state_dict().items()[i][1].data[:]\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.context(x)\n",
        "        x = self.backend(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    if dilation:\n",
        "        d_rate = 2\n",
        "    else:\n",
        "        d_rate = 1\n",
        "    layers = []\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfAW_KQiLRl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CANNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpoV9jEnMmyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d262d706-481e-4929-a99c-4229cf2baf41"
      },
      "source": [
        "\n",
        "checkpoint = torch.load('ALL_WEIGHTS/checkpoint_low_separate.tar')\n",
        "\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vBkUioeMwOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import h5py\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import scipy\n",
        "from image import *\n",
        "from model import CANNet\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxlcWiX2MzkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjSq5MqdM2P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "names = []\n",
        "gt = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-b365zXM88l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute gt for the images\n",
        "for i in xrange(len(lower_training)):\n",
        "    img = transform(Image.open(lower_training[i]).convert('RGB')).cuda()\n",
        "    img = img.unsqueeze(0)\n",
        "    h,w = img.shape[2:4]\n",
        "    h_d = h/2\n",
        "    w_d = w/2\n",
        "    pure_name = os.path.splitext(os.path.basename(lower_training[i]))[0]\n",
        "    gt_file = h5py.File(lower_training[i].replace('.tiff','.h5').replace('images','ground_truth'),'r')\n",
        "    groundtruth = np.asarray(gt_file['density'])\n",
        "    #pred_sum = density_1.sum()+density_2.sum()+density_3.sum()+density_4.sum()\n",
        "    names.append(pure_name)\n",
        "    #round or int give same values\n",
        "    gt.append(round(np.sum(groundtruth)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhrCdowqNLkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrgt = np.asarray(gt)\n",
        "arrnames = np.asarray(names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5YjPhXlNNvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4f5ef04-e318-4d8c-b7ed-cfe38fd4b2ed"
      },
      "source": [
        "print(arrgt.shape)\n",
        "print(arrnames.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1581,)\n",
            "(1581,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uly8Z9LqNR4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "989062ad-0527-4e92-87c3-10daf80302d1"
      },
      "source": [
        "print(arrgt)\n",
        "print(arrnames)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 8. 0.]\n",
            "['IMG_1' 'IMG_2' 'IMG_3' ... 'IMG_1579' 'IMG_1580' 'IMG_1581']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08YcWPcNUNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class featureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(featureExtractor, self).__init__()\n",
        "        self.context = model.context\n",
        "        self.frontend = model.frontend\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.context(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net_conv1 = featureExtractor()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl64ajNENXyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_conv1 = net_conv1.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxj5ndBMQdS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_savepath = 'BEST_TRAIN_LOw/' \n",
        "if not os.path.exists(features_savepath):\n",
        "    os.makedirs(features_savepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN4jcQB5NcDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(features_savepath +'/ground_truth_counts_train_low.npy', arrgt)\n",
        "np.save(features_savepath +'/ground_truth_names_train_low.npy', arrnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZST8gsnPNme7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "82954329-9fe6-4183-8b9d-5a84f57841fb"
      },
      "source": [
        "x =[]\n",
        "y = []\n",
        "for i in xrange(len(lower_training)):\n",
        "    img = transform(Image.open(lower_training[i]).convert('RGB')).cuda()\n",
        "    img = img.unsqueeze(0)\n",
        "    h,w = img.shape[2:4]\n",
        "    density= net_conv1(img).data.cpu().numpy()\n",
        "    act = np.squeeze(density)\n",
        "    pure_name = os.path.splitext(os.path.basename(lower_training[i]))[0]\n",
        "    x.append(act)\n",
        "    y.append(pure_name)\n",
        "\n",
        "    #density = np.squeeze(3)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYqCS84uNyjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s= 0\n",
        "a = 0\n",
        "all_feats =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcObCmBHN0ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(low_train):\n",
        "  feats = []\n",
        "  for j in range(512):\n",
        "    s = 0\n",
        "    for k in range (42):\n",
        "      for l in range(42):\n",
        "        s = s + x[i][j][k][l]\n",
        "    a = s/1764\n",
        "    feats.append(a)\n",
        "  all_feats.append(feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA2F_IgRN4zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = np.array(all_feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_833QJbZgAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a3d3175-b829-47d2-ccee-a7c6070eac67"
      },
      "source": [
        "print(f.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1581, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-xzP4sWQ5LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = 'BEST_TRAIN_LOw/FEATURES/' \n",
        "if not os.path.exists(features):\n",
        "    os.makedirs(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LUTzW6_N92e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(low_train):\n",
        "  x=np.array(f[i])\n",
        "  np.save(features+'/IMG_'+str(i+1)+'.npy',x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}