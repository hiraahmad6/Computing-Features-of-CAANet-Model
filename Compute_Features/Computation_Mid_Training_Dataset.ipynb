{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computation_Mid_Training_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3568f40c2e904309b1e16d02dab01e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_225e5f581a334a89a6dbdfc8b69f1002",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7708a181ba0945debc9cd74b37848ab4",
              "IPY_MODEL_f88b959fca954e01bbe147e135296c39"
            ]
          }
        },
        "225e5f581a334a89a6dbdfc8b69f1002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "width": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "overflow": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "overflow_y": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "align_self": null,
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7708a181ba0945debc9cd74b37848ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b2a0f38e2b147369c5824901560ffd1",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "orientation": "horizontal",
            "min": 0,
            "bar_style": "success",
            "max": 553433881,
            "_model_name": "IntProgressModel",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_346e11aee2c745518cd505d2443a8198",
            "description": ""
          }
        },
        "f88b959fca954e01bbe147e135296c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c371e1352944b669e31b4833b3e9989",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 528M/528M [00:02&lt;00:00, 189MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69482f6aeac9444e9586e0c33a483e1f"
          }
        },
        "2b2a0f38e2b147369c5824901560ffd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "346e11aee2c745518cd505d2443a8198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "width": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "overflow": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "overflow_y": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "align_self": null,
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c371e1352944b669e31b4833b3e9989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69482f6aeac9444e9586e0c33a483e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "width": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "overflow": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "overflow_y": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "align_self": null,
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhT1s_txLmKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mid_train = 2204\n",
        "mid_training =[]\n",
        "\n",
        "for i in range(mid_train):\n",
        "  mid_training.append('part_B_final/train_data/images/IMG_'+str(i+1)+'.tiff')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-her9OiLwhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import dataset\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG3H6NAcLO5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class ContextualModule(nn.Module):\n",
        "    def __init__(self, features, out_features=512, sizes=(1, 2, 3, 6)):\n",
        "        super(ContextualModule, self).__init__()\n",
        "        self.scales = []\n",
        "        self.scales = nn.ModuleList([self._make_scale(features, size) for size in sizes])\n",
        "        self.bottleneck = nn.Conv2d(features * 2, out_features, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.weight_net = nn.Conv2d(features,features,kernel_size=1)\n",
        "\n",
        "    def __make_weight(self,feature,scale_feature):\n",
        "        weight_feature = feature - scale_feature\n",
        "        return F.sigmoid(self.weight_net(weight_feature))\n",
        "\n",
        "    def _make_scale(self, features, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        multi_scales = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.scales]\n",
        "        weights = [self.__make_weight(feats,scale_feature) for scale_feature in multi_scales]\n",
        "        overall_features = [(multi_scales[0]*weights[0]+multi_scales[1]*weights[1]+multi_scales[2]*weights[2]+multi_scales[3]*weights[3])/(weights[0]+weights[1]+weights[2]+weights[3])]+ [feats]\n",
        "        bottle = self.bottleneck(torch.cat(overall_features, 1))\n",
        "        return self.relu(bottle)\n",
        "\n",
        "class CANNet(nn.Module):\n",
        "    def __init__(self, load_weights=False):\n",
        "        super(CANNet, self).__init__()\n",
        "        self.seen = 0\n",
        "        self.context = ContextualModule(512, 512)\n",
        "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
        "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
        "        self.frontend = make_layers(self.frontend_feat)\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 512,batch_norm=True, dilation = True)\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        if not load_weights:\n",
        "            mod = models.vgg16(pretrained = True)\n",
        "            self._initialize_weights()\n",
        "            for i in xrange(len(self.frontend.state_dict().items())):\n",
        "                self.frontend.state_dict().items()[i][1].data[:] = mod.state_dict().items()[i][1].data[:]\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.context(x)\n",
        "        x = self.backend(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    if dilation:\n",
        "        d_rate = 2\n",
        "    else:\n",
        "        d_rate = 1\n",
        "    layers = []\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfAW_KQiLRl1",
        "colab_type": "code",
        "outputId": "7ebb00d9-ebe5-431c-8230-8b9b23f91df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "3568f40c2e904309b1e16d02dab01e96",
            "225e5f581a334a89a6dbdfc8b69f1002",
            "7708a181ba0945debc9cd74b37848ab4",
            "f88b959fca954e01bbe147e135296c39",
            "2b2a0f38e2b147369c5824901560ffd1",
            "346e11aee2c745518cd505d2443a8198",
            "0c371e1352944b669e31b4833b3e9989",
            "69482f6aeac9444e9586e0c33a483e1f"
          ]
        }
      },
      "source": [
        "model = CANNet()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3568f40c2e904309b1e16d02dab01e96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=553433881), HTML(value=u'')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpoV9jEnMmyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b55e2fd0-6811-46ed-9fbd-7cb2302f408b"
      },
      "source": [
        "\n",
        "checkpoint = torch.load('ALL_WEIGHTS/checkpoint_mid_separate.tar')\n",
        "\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vBkUioeMwOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import h5py\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import scipy\n",
        "from image import *\n",
        "from model import CANNet\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxlcWiX2MzkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjSq5MqdM2P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "names = []\n",
        "gt = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-b365zXM88l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute gt for the images\n",
        "for i in xrange(len(mid_training)):\n",
        "    img = transform(Image.open(mid_training[i]).convert('RGB')).cuda()\n",
        "    pure_name = os.path.splitext(os.path.basename(mid_training[i]))[0]\n",
        "    gt_file = h5py.File(mid_training[i].replace('.tiff','.h5').replace('images','ground_truth'),'r')\n",
        "    groundtruth = np.asarray(gt_file['density'])\n",
        "    #pred_sum = density_1.sum()+density_2.sum()+density_3.sum()+density_4.sum()\n",
        "    names.append(pure_name)\n",
        "    #round or int give same values\n",
        "    gt.append(round(np.sum(groundtruth)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhrCdowqNLkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrgt = np.asarray(gt)\n",
        "arrnames = np.asarray(names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5YjPhXlNNvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(arrgt.shape)\n",
        "print(arrnames.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uly8Z9LqNR4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(arrgt)\n",
        "print(arrnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08YcWPcNUNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class featureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(featureExtractor, self).__init__()\n",
        "        self.context = model.context\n",
        "        self.frontend = model.frontend\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.context(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net_conv1 = featureExtractor()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl64ajNENXyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_conv1 = net_conv1.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxj5ndBMQdS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_savepath = 'BEST_TRAIN_MID/' \n",
        "if not os.path.exists(features_savepath):\n",
        "    os.makedirs(features_savepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN4jcQB5NcDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(features_savepath +'/ground_truth_counts_train_mid.npy', arrgt)\n",
        "np.save(features_savepath +'/ground_truth_names_train_mid.npy', arrnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZST8gsnPNme7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "82954329-9fe6-4183-8b9d-5a84f57841fb"
      },
      "source": [
        "x =[]\n",
        "y = []\n",
        "for i in xrange(len(mid_training)):\n",
        "    img = transform(Image.open(mid_training[i]).convert('RGB')).cuda()\n",
        "    img = img.unsqueeze(0)\n",
        "    h,w = img.shape[2:4]\n",
        "    density= net_conv1(img).data.cpu().numpy()\n",
        "    act = np.squeeze(density)\n",
        "    pure_name = os.path.splitext(os.path.basename(mid_training[i]))[0]\n",
        "    x.append(act)\n",
        "    y.append(pure_name)\n",
        "\n",
        "    #density = np.squeeze(3)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYqCS84uNyjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s= 0\n",
        "a = 0\n",
        "all_feats =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcObCmBHN0ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(mid_train):\n",
        "  feats = []\n",
        "  for j in range(512):\n",
        "    s = 0\n",
        "    for k in range (42):\n",
        "      for l in range(42):\n",
        "        s = s + x[i][j][k][l]\n",
        "    a = s/1764\n",
        "    feats.append(a)\n",
        "  all_feats.append(feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA2F_IgRN4zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = np.array(all_feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_833QJbZgAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-xzP4sWQ5LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = 'BEST_TRAIN_MID/FEATURES/' \n",
        "if not os.path.exists(features):\n",
        "    os.makedirs(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LUTzW6_N92e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(mid_train):\n",
        "  x=np.array(f[i])\n",
        "  np.save(features+'/IMG_'+str(i+1)+'.npy',x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}